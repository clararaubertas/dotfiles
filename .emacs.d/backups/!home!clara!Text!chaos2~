CHAOS YO

"Chaos was the law of nature; Order was the dream of man." -- Henry
Adams, The Education of Henry Adams

What is chaos? Intuitively, we think of it as randomness,
unpredictability, a state of total confusion. But in the context of
information theory and complexity, it has a more specific meaning. A
chaotic phenomenon is one that is ultimately deterministic, but very
sensitive to initial conditions. In a deterministic process, the final
outcome is completely defined by the combination of the initial
conditions and a well-defined, predictable process -- often a very
simple one. But in the chase of chaos, which is a subset of
determinism, the outcomes diverge exponentially from any change in the
initial conditions, even a change so small as to be imperceptible. So
events in chaotic systems appear totally random to a human observer,
although they are actually predictable from simple deterministic
equations.

What does this mean in practice? It means it's essentially impossible
to predict the future behavior of chaotic systems, despite their total
determinism. Even a very small error in calculating the initial
conditions will quickly multiply into a very large error in predicting
future conditions. One of the clearest examples of this phenomenon is
weather. While in theory, weather should be totally predictable --
today's weather follows yesterday's weather based on well-known
physical events, so we ought to be able to compute tomorrow's weather
from today's, and the next day's from tomorrow's, and so on
indefinitely, with total accuracy. But in reality, even the most
accurate meteorologists can only predict the weather about a week out.
This is because even the tiniest error or even rounding in measuring
the initial conditions will have an exponential effect on the later
outcome.

“It is impossible to trap modern physics into predicting anything with
perfect determinism because it deals with probabilities from the
outset.” ― Arthur Eddington

A deterministic system is one that is totally predictable in theory --
each state of the system is determined from the previous state with no
random or probabilistic element. This is the picture of the world that
Newton and classical physicists had. On the other side, a
probabilistic system includes elements of randomness -- so starting
with identical inputs does not guarantee you identical outputs. This
is the picture of the world that modern quantum physicists have. At
first glance, it might seem important to know which of these ways the
world actually works, since a deterministic world would imply that we
could predict and perhaps even control the future. But chaos theory
tells us that this isn't the case -- that even in a completely
deterministic world, some phenomena would still be impossible to
predict in practice.

"Exponentials can't go on forever, because they will gobble up
everything." -- Carl Sagan

Exponential growth is hard to comprehend intuitively -- something that
is growing exponentially gets much bigger, much faster, than most
people would expect. It doesn't even really matter what the exponent
is because the rate of growth is so extreme. This concept is often
illustrated by a Persian legend about the invention of chess (dating
back to about 1000 CE!). In the legend, the inventor of chess shows
the chessboard to a ruler, and the ruler is so pleased he invites the
inventor to name his own reward. The inventor asks for one grain of
rice for the first square of the chessboard, two for the second
square, four for the third, and so forth. The ruler is insulted that
the inventor is asking for what seems like a low price -- however,
when you add this up, it's not a low price at all! By the 64th square
of the chessboard there are 18,446,744,073,709,551,615 grains of rice
-- a pile of rice larger than Mount Everest. And this is using the
exponent of 2, the smallest possible. Each square of the chessboard
has more grains of rice than the total of all the squares before it.
While exponential growth may seem trivial for the first few iterations
(2, 4, 8, 16...), it will fairly quickly reach almost unimaginable
sizes. So the important thing to remember about exponential growth is
that nothing growing less than exponentially can ever come even
remotely close to catching up.

"Crushing certain plants could add up infinitesimally. A little error
here would multiply in sixty million years, all out of proportion." --
A Sound of Thunder

This phenomenon was discovered by accident by Edward Lorenz, who was
writing computer models to attempt to predict and simulate weather.
One day he had to stop his simulation before reaching his goal, and
rather than start over from the initial input, he fed the numbers from
the printout of some intermediate results back into the computer,
hoping to save computation time. To his surprise, the results from the
second run were wildly different. After double-checking the data he
had entered from the printout, he realized that the computer was
storing its numbers to a slightly higher degree of accuracy than what
he'd seen on the printout -- the printout truncated the long decimals
slightly sooner than the computer's internal representation. As Lorenz
later quipped, "Chaos: When the present determines the future, but the
approximate present does not approximately determine the future." This
was contrary to the assumptions that Lorenz and most other scientists
of the time had made about the deterministic universe, and contrary to
the more easily-understandable linear dynamics (e.g. predicting the
trajectory of a shotgun shell or the orbit of a planet, where the
approximate present *does* approximately determine the future).


"Anyone who believes in indefinite growth in anything physical, on a
physically finite planet, is either mad - or an economist." -- Kenneth
Boulding, US Congress 1973 (adviser to JFK)

This sensitivity to initial conditions is commonly called the
butterfly effect (the name Lorenz gave to his observation), since it
implies that something as imperceptible as the flapping of a
butterfly's wings will have far-reaching (but unpredictable in
practical terms) effects on the entire weather system. So if we fail
to account for this butterfly when setting up the initial conditions
for any hopefully-omniscient weather predictor, our system becomes
totally worthless down the line -- and since there's *always* going to
be something as small as the butterfly slipping through the cracks of
our initial conditions at the level we can record them, we're *never*
going to be able to accurately predict the weather on this day next
year.

We can illustrate this with a function called the logistic map, a
fairly simple mathematical equation often used to illustrate the onset
of chaos. This function roughly describes the idea of a population
rising and falling over successive generations based on whether there
is enough food to support it. You start with an input between 0 and 1,
representing the percent of the largest possible population that's
currently existing, and then you iterate this function -- (lambda *
input * (1 - input)) -- on it, replacing the input with the output
from the previous iteration each time. The thing about the function is
that the function varies based on a parameter usually called "lambda"
-- and we see some interesting results. When lambda is between 0 and
1, the population always eventually dies. When lambda is between 1 and
3, the population converges on a value of (lambda - 1)/lambda. Then
things get interesting. When it's between 3 and 3.449, the population
converges on an oscillation between 2 values. When it's between 3.449
and 3.544, the population converges on an oscillation between 4
values. When it's between 3.544 and 3.569, the population converges on
an oscillation between several values. When it's over 4, the values
leave the meaningful interval [0,1] and diverge. But in that key tiny
interval -- when the logistic map function is generated with a lambda
between 3.569 and 4 -- the output is chaotic, and *never* converges on
either a value or a steady period of repetitions. We now have no way
of knowing what will happen to our population in the future -- and the
outcome for any input is arbitrarily far away from the outcome for an
arbitrarily similar but not identical input. A key fact here is to
notice that there is *no random parameter anywhere in the equation*.
We started with total determinism, and we reached complete
unpredictability, without ever introducing randomness or probabilistic
effects into our system.

"And chaos theory teaches us…that straight linearity, which we have
come to take for granted in everything from physics to fiction, simply
does not exist. Linearity is an artificial way of viewing the world.
Real life isn't a series of interconnected events occurring one after
another like beads strung on a necklace. Life is actually a series of
encounters in which one event may change those that follow in a wholly
unpredictable, even devastating way." -- Ian Malcolm, Jurassic Park
(the novel) (by Michael Crichton)

Despite how complicated and unintuitive chaotic systems may seem, we
actually do naturally understand this phenomenon on a highly intuitive
level. Sensitivity to initial conditions resonates with us in popular
culture and in our ordinary lives, and the term "butterfly effect" has
become popular for everyday use. We often think, "If only I had done
something slightly different in the past, things would be very
different now!" One pop culture example is the movie Sliding Doors,
which tells the two stories of Gwyneth Paltrow's character either
barely making a particular subway train or arriving a few seconds
later as the doors are closing. The life events of the two versions of
the character quickly diverge -- and these drastically different
outcomes triggered by a seemingly small and pointless initial
difference make natural sense even to viewers with no knowledge of
chaos and complexity.

One might respond ot this by saying, "Oh, I must have forgotten a
parameter!", and fantasize that the unpredictability stemmed only from
forgetting to include the subway doors in your calculation. But what
chaos theory states is that differences in outcomes grow exponentially
from differences in inputs -- and exponential growth is something we
can never catch up with. In Ray Bradbury's Twilight Zone-esque 'A
Sound of Thunder' -- written in 1952, years before Lorenz -- he
describes a time-travel tourism agency that impresses on its clients
that while in the past they must not stray from the path set out for
them, since even the tiniest change would ripple out into a major
difference in the present. And indeed, when the story's central
character steps on a butterfly in the past, he returns to a future
altered for the worse. Bradbury's conception recognizes that making a
tiny change to the past doesn't just enter one in a lottery of
possible changes to the future -- any tiny change *will* cause these
ripples.

“Insofar as we appreciate order, it is when we perceive it as being
accompanied by complexity, when we feel that a variety of elements has
been brought to order--that windows, doors and other details have been
knitted into a scheme that manages to be at once regular and
intricate." -- Alain de Botton

Complexity, in the sense of "complex systems", is sometimes referred
to as "the edge of chaos" -- and this is the level of information
density humans like best. (This isn't the same as "complexity theory",
which usually refers to the discussion of "complexity classes" -- see
Eric's piece in this issue for more on that kind of complexity.) It's
a level of predictability in between that of a highly chaotic system
-- which quickly looks random -- and that of a linearly determined
system -- which is easily predictable at every stage. Totally random
data contains no information, and is uninteresting. Totally
predictable data contains very little information, and is
uninteresting. But complex data, lying on the edge of chaos in between
these extremes, is what engages the human brain.

This kind of complexity is what leads to emergent systems, where
high-level interesting properties and even apparent intentionality or
emerge from very simple low-level interactions. This happens in ant
colonies, geopolitical events, in stock market fluctuations, in the
evolution of specialized body parts, and in the organization of city
neighborhoods. Complexity is also sometimes called "self-organized
criticality". It can be seen in simulations like John Conway's "Game
of Life", where a random set of initial conditions and a very simple
process for moving from one state to the next leads to a visible level
of organization -- the organization seems to come for "free", since
neither the initial conditions nor the process of change contain the
patterns that they combine to produce.

In some sense, systems "want" to be at this edge of chaos, where phase
transitions -- like water turning to ice, or a pile of snow collapsing
into an avalanche -- occur. These systems resemble each other on a
broad structural level -- the phase transitions, the waves of change
and upheaval, follow a power law distribution (small earthquakes are
exponentially more likely than large ones) on every scale (like
fractals, which are also complex and self-similar on every level).

“If life were predictable it would cease to be life, and be without
flavor.” -- Eleanor Roosevelt

Chaos is a kind of paradox -- from complete determinism, comes utter
unpredictability. And complex systems are another kind of paradox --
interesting patterns coming out of uninteresting inputs and laws. Blah
blah I hate writing conclusions. Therefore, you have just finished
reading some kind of essay. Ta-da!
